{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b22c3b9d",
   "metadata": {},
   "source": [
    "## 1. What is PyTorch? The Core Idea ðŸ’¡\n",
    "\n",
    "At its heart, PyTorch is a Python library for scientific computing that's loved by researchers and developers for its simplicity and power. It provides two main features that make it perfect for deep learning:\n",
    "\n",
    "* **Tensors:** These are multi-dimensional arrays, similar to NumPy arrays. The superpower of PyTorch tensors is that they can be easily moved to a **GPU** for massive speedups in computation.\n",
    "* **Automatic Differentiation:** PyTorch can automatically calculate gradients (derivatives). This is the magic that allows neural networks to \"learn\" from data, and it's managed by a system called `autograd`.\n",
    "\n",
    "It's known for being \"Pythonic,\" meaning its design feels natural and intuitive to anyone familiar with Python. Let's dive into the most fundamental building block: the Tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68e4017b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version: 2.7.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Print the PyTorch version we are using\n",
    "print(f\"PyTorch Version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59adf4fe",
   "metadata": {},
   "source": [
    "## 2. The Building Blocks: PyTorch Tensors ðŸ§±\n",
    "\n",
    "Everything in PyTorch revolves around the **Tensor**. A tensor is a number, vector, matrix, or any n-dimensional array. It's the primary data structure we'll be working with.\n",
    "\n",
    "### Creating Tensors\n",
    "\n",
    "You can create tensors in several ways.\n",
    "\n",
    "#### From a Python list:\n",
    "\n",
    "The most basic way is to create a tensor directly from a Python list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a6868a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a simple 1-dimensional tensor (a vector)\n",
    "data = [[1, 2], [3, 4]]\n",
    "my_tensor = torch.tensor(data)\n",
    "\n",
    "my_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a8a3b9",
   "metadata": {},
   "source": [
    "#### From a NumPy array:\n",
    "\n",
    "PyTorch integrates seamlessly with NumPy. You can create a tensor from a NumPy array and vice-versa. This is incredibly useful since many data processing libraries (like Scikit-learn, Pandas) are built on NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8329fe84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy array:\n",
      " [[5. 6.]\n",
      " [7. 8.]]\n",
      "\n",
      "Tensor from NumPy:\n",
      " tensor([[5., 6.],\n",
      "        [7., 8.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# Create a NumPy array\n",
    "numpy_array = np.array([[5., 6.], [7., 8.]])\n",
    "print(f\"NumPy array:\\n {numpy_array}\\n\")\n",
    "\n",
    "# Convert NumPy array to a PyTorch tensor\n",
    "numpy_to_tensor = torch.from_numpy(numpy_array)\n",
    "print(f\"Tensor from NumPy:\\n {numpy_to_tensor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cdbe1d0",
   "metadata": {},
   "source": [
    "#### Using built-in functions:\n",
    "\n",
    "PyTorch also provides functions to create tensors with specific shapes and values, which is very common when initializing a neural network's weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26ef3b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor of ones:\n",
      " tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]])\n",
      "\n",
      "Tensor of zeros:\n",
      " tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "\n",
      "Random tensor:\n",
      " tensor([[ 0.2199,  2.2317, -0.6550, -0.5441],\n",
      "        [ 0.6989, -0.1054,  0.1954,  0.3632],\n",
      "        [-0.0730, -0.3862, -0.1804, -0.7214]])\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor of shape (3, 4) with all ones\n",
    "ones_tensor = torch.ones(3, 4)\n",
    "print(f\"Tensor of ones:\\n {ones_tensor}\\n\")\n",
    "\n",
    "# Create a tensor of shape (3, 4) with all zeros\n",
    "zeros_tensor = torch.zeros(3, 4)\n",
    "print(f\"Tensor of zeros:\\n {zeros_tensor}\\n\")\n",
    "\n",
    "# Create a tensor of shape (3, 4) with random numbers from a standard normal distribution\n",
    "random_tensor = torch.randn(3, 4)\n",
    "print(f\"Random tensor:\\n {random_tensor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e91ccd1",
   "metadata": {},
   "source": [
    "### Tensor Attributes\n",
    "\n",
    "A tensor has attributes that describe its `shape`, `dtype` (data type), and the `device` (CPU or GPU) where it's stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7dbcf09b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor: torch.Size([3, 4])\n",
      "Datatype of tensor: torch.float32\n",
      "Device tensor is stored on: cpu\n"
     ]
    }
   ],
   "source": [
    "# Let's inspect our random tensor\n",
    "print(f\"Shape of tensor: {random_tensor.shape}\")\n",
    "print(f\"Datatype of tensor: {random_tensor.dtype}\")\n",
    "print(f\"Device tensor is stored on: {random_tensor.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8731c119",
   "metadata": {},
   "source": [
    "### Moving Tensors to the GPU\n",
    "\n",
    "One of the key advantages of PyTorch is its ability to perform computations on a GPU for significant speed-ups. You can check if a GPU is available and move your tensor to it using the `.to()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f25351e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple Silicon GPU (MPS) is available! We'll use the GPU.\n",
      "\n",
      "Our random tensor is now on: mps:0\n"
     ]
    }
   ],
   "source": [
    "# 1. Check for Apple Silicon GPU (MPS)\n",
    "if torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "    print(\"Apple Silicon GPU (MPS) is available! We'll use the GPU.\")\n",
    "# 2. Check for NVIDIA GPU (CUDA)\n",
    "elif torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "    print(\"NVIDIA GPU (CUDA) is available! We'll use the GPU.\")\n",
    "# 3. Fallback to CPU\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "    print(\"No GPU available, we'll use the CPU.\")\n",
    "\n",
    "# --- Using the Device ---\n",
    "\n",
    "random_tensor = torch.randn(3, 4)\n",
    "\n",
    "# Move our tensor to the selected device\n",
    "tensor_on_device = random_tensor.to(device)\n",
    "print(f\"\\nOur random tensor is now on: {tensor_on_device.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a6f5ac",
   "metadata": {},
   "source": [
    "### Tensor Operations\n",
    "\n",
    "Operations on tensors work much like you'd expect. We can perform standard arithmetic in an intuitive way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291a013c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t1 : tensor([[1, 2],\n",
      "        [3, 4]], dtype=torch.int32)\n",
      "t2 : tensor([[10, 10],\n",
      "        [10, 10]], dtype=torch.int32)\n",
      "t1 dtype: torch.int32\n",
      "t2 dtype: torch.int32\n",
      "\n",
      "Addition:\n",
      " tensor([[11, 12],\n",
      "        [13, 14]], dtype=torch.int32)\n",
      "\n",
      "Multiplication:\n",
      " tensor([[10, 20],\n",
      "        [30, 40]], dtype=torch.int32)\n",
      "\n",
      "Matrix Multiplication:\n",
      " tensor([[30, 30],\n",
      "        [70, 70]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "# Let's create two tensors with the SAME dtype\n",
    "t1 = torch.tensor([[1, 2], [3, 4]], dtype=torch.int32)\n",
    "t2 = torch.ones(2, 2, dtype=torch.int32) * 10 # Creates a 2x2 tensor of 10s\n",
    "\n",
    "print(f\"t1 : {t1}\")\n",
    "print(f\"t2 : {t2}\")\n",
    "\n",
    "# check their dtypes\n",
    "print(f\"t1 dtype: {t1.dtype}\")\n",
    "print(f\"t2 dtype: {t2.dtype}\\n\")\n",
    "\n",
    "# Addition\n",
    "print(\"Addition:\\n\", t1 + t2)\n",
    "\n",
    "# Element-wise multiplication\n",
    "print(\"\\nMultiplication:\\n\", t1 * t2)\n",
    "\n",
    "# Matrix multiplication\n",
    "print(\"\\nMatrix Multiplication:\\n\", t1.matmul(t2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08925f6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (base)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
